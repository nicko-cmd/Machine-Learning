{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"file_training.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Oxd01s-qdz2Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"fa443aa3-2ed6-4ffb-c1c5-f22581e6fe34","executionInfo":{"status":"ok","timestamp":1582478796924,"user_tz":-60,"elapsed":33899,"user":{"displayName":"ARMANDO CAVALLARO","photoUrl":"","userId":"03353889045510786986"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TBjD_HxAd22-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":180},"outputId":"5bee2762-6273-4a32-b233-155261a232be","executionInfo":{"status":"error","timestamp":1582478803659,"user_tz":-60,"elapsed":931,"user":{"displayName":"ARMANDO CAVALLARO","photoUrl":"","userId":"03353889045510786986"}}},"source":["import os\n","os.chdir('/content/drive/My Drive/Machine Learning/Contest2019/AgeComparison')"],"execution_count":3,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-3a1c5b4a9650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Machine Learning/Contest2019/AgeComparison'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Machine Learning/Contest2019/AgeComparison'"]}]},{"cell_type":"code","metadata":{"id":"T3qmZm-zeDM5","colab_type":"code","colab":{}},"source":["!pip install keras_vggface\n","import numpy as np\n","import tensorflow as tf\n","import random\n","from keras.models import Model\n","from keras import backend as K\n","from keras_vggface import VGGFace\n","from keras.optimizers import Adam\n","from keras.layers import Concatenate, Dropout,GlobalAveragePooling2D, Input,BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dense, Input, Lambda\n","from keras.models import Model, Sequential\n","from keras.regularizers import l2\n","import keras\n","from keras_vggface import VGGFace"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZvsfrYn6d4ya","colab_type":"code","colab":{}},"source":["def get_model(input_shape=(192, 192, 3)):\n","    #pre_trained=InceptionV3(weights=\"imagenet\")\n","    resize = keras.layers.Lambda( \n","    lambda image: tf.image.resize_images( \n","            image, \n","            (224, 224), \n","            method = tf.image.ResizeMethod.BICUBIC,\n","            align_corners = True, # possibly important\n","            preserve_aspect_ratio = True\n","        )\n","    )\n","\n","    inp = Input(shape=(192, 192, 3))\n","    res = resize(inp)\n","    # add a global spatial average pooling layer\n","    base_model = VGGFace(input_tensor=res, pooling='avg')\n","    x = base_model.layers[-7].output    \n","    normalize = Lambda(lambda x: K.l2_normalize(x, axis=-1), name='normalize')\n","    x=normalize(x)\n","    x = Dense(128, activation=\"relu\")(x)\n","    x = Dropout(0.5)(x)\n","    model = Model(inputs=inp, outputs=x)\n","\n","    return model\n","\n","base_model = get_model()\n","\n","xa_inp = Input(shape=(192, 192, 3))\n","xb_inp = Input(shape=(192, 192, 3))\n","x1=base_model(xa_inp)\n","x2=base_model(xb_inp)\n","out = Concatenate()([x1, x2])\n","out = Dense(3, activation=\"softmax\")(out)\n","model = Model(inputs=[xa_inp,xb_inp], outputs=out)\n","\n","\n","opt = Adam(lr=1e-5)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KbWLMRhpebb5","colab_type":"code","colab":{}},"source":["import h5py\n","\n","f=h5py.File('train_set_shuffled.h5', 'r')\n","# NOTE! We don't make a in-memory copy of the dataset... So we cannot close the file!\n","\n","X1=f['X1']   # Tensor with first images in the pair\n","X2=f['X2']   # Tensor with second images in the pair\n","y=f['y']     # Tensor with desired output\n","\n","\n","print(X1.shape, X2.shape, y.shape)\n","\n","import numpy as np\n","\n","train = 0.80 \n","test = 0.10\n","val = 0.10\n","\n","#Splitting \n","x1_val = X1[:int(X1.shape[0]*val)]\n","x2_val = X2[:int(X1.shape[0]*val)]\n","y_val = y[:int(X1.shape[0]*val)]\n","print(\"Done val\")\n","x1_train = X1[int(X1.shape[0]*val):]\n","x2_train = X2[int(X1.shape[0]*val):]\n","y_train = y[int(X1.shape[0]*val):] \n","print(\"Done train\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zo4YKCnnenPS","colab_type":"code","colab":{}},"source":["#Generators\n","import numpy as np\n","from PIL import Image, ImageEnhance\n","from keras.preprocessing.image import img_to_array, array_to_img\n","import random\n","\n","def random_brightness(x, interval=[0.5, 1.5]):        \n","    apply = np.random.randint(0,2)\n","    if apply:\n","        value = random.uniform(interval[0],interval[1])\n","        img = array_to_img(x)\n","        enhancer = ImageEnhance.Brightness(img)\n","        enhancer.enhance(value)\n","        x = img_to_array(img)    \n","    return x\n","    \n","\n","def generate_val(batch_size):\n","    x1_batch, x2_batch, y_batch = [],[],[]\n","    \n","    while len(x1_batch)<batch_size:\n","        index = np.random.randint(0,x1_val.shape[0])\n","        x1, x2, y = x1_val[index], x2_val[index], y_val[index]\n","        x1_batch.append(x1)\n","        x2_batch.append(x2)\n","        y_batch.append(y)\n","        \n","    return [np.array(x1_batch)/255.0, np.array(x2_batch)/255.0], np.array(y_batch)\n","    \n","\n","def generate_train(batch_size):\n","    x1_batch, x2_batch, y_batch = [],[],[]\n","    left, center, right = 0, 0, 0\n","    \n","    while len(x1_batch)<batch_size:\n","        index = np.random.randint(0,x1_train.shape[0])\n","        \n","        #Prendo, nel batch, un numero uguale di classi\n","        if y_train[index][0] and left >= batch_size//3:\n","            continue\n","        if y_train[index][1] and center >= batch_size//3:\n","            continue\n","        if y_train[index][2] and right >= batch_size//3:\n","            continue\n","        \n","        x1, x2, y = x1_train[index], x2_train[index], y_train[index]\n","        x1=random_brightness(x1)\n","        x2=random_brightness(x2)\n","        \n","        x1_batch.append(x1)\n","        x2_batch.append(x2)\n","        y_batch.append(y)\n","        \n","        x1, x2 = np.flip(x1, axis=1), np.flip(x2,axis=1)\n","        x1=random_brightness(x1)\n","        x2=random_brightness(x2)\n","        \n","        x1_batch.append(x1)\n","        x2_batch.append(x2)\n","        y_batch.append(y)\n","        \n","        if y[0]:\n","            left+=2\n","        elif y[1]:\n","            center+=2\n","        else:\n","            right+=2\n","    return [np.array(x1_batch)/255.0, np.array(x2_batch)/255.0], np.array(y_batch)\n","\n","\n","\n","def generate_train_batch(batch_size):\n","    while True:\n","        yield generate_train(batch_size)\n","\n","def generate_val_batch(batch_size):\n","    while True:\n","        yield generate_val(batch_size)\n","    \n","for (x1,x2),y in generate_val_batch(17):\n","    print(x1.shape)\n","    print(np.sum(y, axis=0))\n","    break"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c0NeqEvoe35R","colab_type":"code","colab":{}},"source":["import keras\n","\n","filepath = \"siamese.{epoch:02d}-{val_loss:.2f}.hdf5\"\n","\n","callbacks= [ keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=10)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"inUx7uQEfBeB","colab_type":"code","colab":{}},"source":["batch_size=33\n","\n","nb_train = y_train.shape[0]/batch_size\n","nb_validation = y_val.shape[0]/batch_size\n","history = model.fit_generator(\n","                    generate_train_batch(batch_size),\n","                    steps_per_epoch=nb_train,\n","                    epochs=100,\n","                    validation_data=generate_val_batch(batch_size),\n","                    validation_steps=nb_validation,\n","                    verbose=1, callbacks=callbacks)"],"execution_count":0,"outputs":[]}]}