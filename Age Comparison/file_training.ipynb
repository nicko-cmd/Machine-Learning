{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "file_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3qmZm-zeDM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install keras_vggface"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxd01s-qdz2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBjD_HxAd22-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Machine Learning/Contest2019/AgeComparison')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZTIfPGo82OZ",
        "colab_type": "text"
      },
      "source": [
        "#Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbWLMRhpebb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "f=h5py.File('train_set_shuffled.h5', 'r')\n",
        "# NOTE! We don't make a in-memory copy of the dataset... So we cannot close the file!\n",
        "\n",
        "X1=f['X1']   # Tensor with first images in the pair\n",
        "X2=f['X2']   # Tensor with second images in the pair\n",
        "y=f['y']     # Tensor with desired output\n",
        "\n",
        "\n",
        "print(X1.shape, X2.shape, y.shape)\n",
        "\n",
        "train = 0.80 \n",
        "test = 0.10\n",
        "val = 0.10\n",
        "\n",
        "#Splitting \n",
        "x1_val = X1[:int(X1.shape[0]*val)]\n",
        "x2_val = X2[:int(X1.shape[0]*val)]\n",
        "y_val = y[:int(X1.shape[0]*val)]\n",
        "\n",
        "x1_train = X1[int(X1.shape[0]*val):]\n",
        "x2_train = X2[int(X1.shape[0]*val):]\n",
        "y_train = y[int(X1.shape[0]*val):] \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4eJeGCP8vlf",
        "colab_type": "text"
      },
      "source": [
        "#Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvsfrYn6d4ya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras_vggface import VGGFace\n",
        "from keras.layers import Input, Lambda, Dense, Dropout, Concatenate\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "\n",
        "\n",
        "def get_model(input_shape=(192, 192, 3)):\n",
        "    resize = Lambda(lambda image: tf.image.resize_images( \n",
        "            image, \n",
        "            (224, 224), \n",
        "            method = tf.image.ResizeMethod.BICUBIC,\n",
        "            align_corners = True, # possibly important\n",
        "            preserve_aspect_ratio = True\n",
        "        )\n",
        "    )\n",
        "\n",
        "    inp = Input(shape=(192, 192, 3))\n",
        "    res = resize(inp)\n",
        "    # add a global spatial average pooling layer\n",
        "    base_model = VGGFace(input_tensor=res, pooling='avg')\n",
        "    x = base_model.layers[-7].output    \n",
        "    normalize = Lambda(lambda x: K.l2_normalize(x, axis=-1), name='normalize')\n",
        "    x = normalize(x)\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "\n",
        "    return model\n",
        "\n",
        "base_model = get_model()\n",
        "\n",
        "xa_inp = Input(shape=(192, 192, 3))\n",
        "xb_inp = Input(shape=(192, 192, 3))\n",
        "x1 = base_model(xa_inp)\n",
        "x2 = base_model(xb_inp)\n",
        "out = Concatenate()([x1, x2])\n",
        "out = Dense(3, activation=\"softmax\")(out)\n",
        "model = Model(inputs=[xa_inp,xb_inp], outputs=out)\n",
        "\n",
        "opt = Adam(lr=1e-5)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMYrX4e1-4t1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEucUS1i8UDs",
        "colab_type": "text"
      },
      "source": [
        "#Generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo4YKCnnenPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image, ImageEnhance\n",
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def random_brightness(x, interval=[0.5, 1.5]):        \n",
        "    apply = np.random.randint(0,2)\n",
        "    if apply:\n",
        "        value = random.uniform(interval[0],interval[1])\n",
        "        img = array_to_img(x)\n",
        "        enhancer = ImageEnhance.Brightness(img)\n",
        "        enhancer.enhance(value)\n",
        "        x = img_to_array(img)    \n",
        "    return x\n",
        "    \n",
        "\n",
        "def generate_val(batch_size):\n",
        "    x1_batch, x2_batch, y_batch = [],[],[]\n",
        "    \n",
        "    while len(x1_batch)<batch_size:\n",
        "        index = np.random.randint(0,x1_val.shape[0])\n",
        "        x1, x2, y = x1_val[index], x2_val[index], y_val[index]\n",
        "        x1_batch.append(x1)\n",
        "        x2_batch.append(x2)\n",
        "        y_batch.append(y)\n",
        "        \n",
        "    return [np.array(x1_batch)/255.0, np.array(x2_batch)/255.0], np.array(y_batch)\n",
        "    \n",
        "\n",
        "def generate_train(batch_size):\n",
        "    x1_batch, x2_batch, y_batch = [],[],[]\n",
        "    left, center, right = 0, 0, 0\n",
        "    \n",
        "    while len(x1_batch)<batch_size:\n",
        "        index = np.random.randint(0,x1_train.shape[0])\n",
        "        \n",
        "        #Prendo, nel batch, un numero uguale di classi\n",
        "        if y_train[index][0] and left >= batch_size//3:\n",
        "            continue\n",
        "        if y_train[index][1] and center >= batch_size//3:\n",
        "            continue\n",
        "        if y_train[index][2] and right >= batch_size//3:\n",
        "            continue\n",
        "        \n",
        "        x1, x2, y = x1_train[index], x2_train[index], y_train[index]\n",
        "        x1 = random_brightness(x1)\n",
        "        x2 = random_brightness(x2)\n",
        "        \n",
        "        x1_batch.append(x1)\n",
        "        x2_batch.append(x2)\n",
        "        y_batch.append(y)\n",
        "        \n",
        "        x1, x2 = np.flip(x1, axis=1), np.flip(x2,axis=1)\n",
        "        x1 = random_brightness(x1)\n",
        "        x2 = random_brightness(x2)\n",
        "        \n",
        "        x1_batch.append(x1)\n",
        "        x2_batch.append(x2)\n",
        "        y_batch.append(y)\n",
        "        \n",
        "        if y[0]:\n",
        "            left+=2\n",
        "        elif y[1]:\n",
        "            center+=2\n",
        "        else:\n",
        "            right+=2\n",
        "    return [np.array(x1_batch)/255.0, np.array(x2_batch)/255.0], np.array(y_batch)\n",
        "\n",
        "\n",
        "\n",
        "def generate_train_batch(batch_size):\n",
        "    while True:\n",
        "        yield generate_train(batch_size)\n",
        "\n",
        "def generate_val_batch(batch_size):\n",
        "    while True:\n",
        "        yield generate_val(batch_size)\n",
        "    \n",
        "for (x1,x2),y in generate_val_batch(17):\n",
        "    print(x1.shape)\n",
        "    print(np.sum(y, axis=0))\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJBzBwB78XqU",
        "colab_type": "text"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHzjvkZW8cHU",
        "colab_type": "text"
      },
      "source": [
        "##Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0NeqEvoe35R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "\n",
        "filepath = \"siamese.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', \n",
        "                                            verbose=1, save_best_only=True, \n",
        "                                            save_weights_only=False, mode='auto', \n",
        "                                            period=10)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtnaxjaR8zBJ",
        "colab_type": "text"
      },
      "source": [
        "##Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inUx7uQEfBeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size =33\n",
        "\n",
        "nb_train = y_train.shape[0]/batch_size\n",
        "nb_validation = y_val.shape[0]/batch_size\n",
        "history = model.fit_generator(\n",
        "                    generate_train_batch(batch_size),\n",
        "                    steps_per_epoch=nb_train,\n",
        "                    epochs=100,\n",
        "                    validation_data=generate_val_batch(batch_size),\n",
        "                    validation_steps=nb_validation,\n",
        "                    verbose=1, callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}